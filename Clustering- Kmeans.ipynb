{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfe5ef1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp39-cp39-win_amd64.whl (23.9 MB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\skand\\anaconda3\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\skand\\anaconda3\\lib\\site-packages (from gensim) (1.20.3)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.0.0-py3-none-any.whl (58 kB)\n",
      "Collecting Cython==0.29.28\n",
      "  Downloading Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n",
      "Installing collected packages: smart-open, Cython, gensim\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.24\n",
      "    Uninstalling Cython-0.29.24:\n",
      "      Successfully uninstalled Cython-0.29.24\n",
      "Successfully installed Cython-0.29.28 gensim-4.2.0 smart-open-6.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22a90013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d739294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\skand\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edcd154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gensim\n",
      "Version: 4.2.0\n",
      "Summary: Python framework for fast Vector Space Modelling\n",
      "Home-page: http://radimrehurek.com/gensim\n",
      "Author: Radim Rehurek\n",
      "Author-email: me@radimrehurek.com\n",
      "License: LGPL-2.1-only\n",
      "Location: c:\\users\\skand\\anaconda3\\lib\\site-packages\n",
      "Requires: smart-open, scipy, Cython, numpy\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c88b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import tqdm as tqdm\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words(\"english\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "english_stemmer=nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from math import floor,ceil\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f163fd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cluster_id                                id  \\\n",
      "0             0  0334a0d055104e9a931c079e338be9a1   \n",
      "1             0  796d6c25ab8849cbba427f1f3e250d80   \n",
      "2             0  661f5299cd8944a8a3841fd4f049dee9   \n",
      "3             0  da831e4bc58d4505aec3c583f0248f8b   \n",
      "4             0  0ea997675e7344419d1540d3e0bc26c3   \n",
      "..          ...                               ...   \n",
      "599          10  93f874167d11473f8d36d1cda0a0081c   \n",
      "600          10  d50fe37fab064408a891aa9ef45dcd70   \n",
      "601          10  3e1e8901d5ab4fc9b602ecfdca1220cb   \n",
      "602          10  c84e1b1196a242d18938af6c60403afc   \n",
      "603          10  fd4c71f399104d59ad6c1013fc414c67   \n",
      "\n",
      "                                                phrase     common idea  \n",
      "0          Would use the product again if needed Joe .  loyal customer  \n",
      "1           Have been using the product for a week now  loyal customer  \n",
      "2    Will continue to use this product when I have ...  loyal customer  \n",
      "3        Have always had good luck with this product .  loyal customer  \n",
      "4    Will continue to use This product as This prod...  loyal customer  \n",
      "..                                                 ...             ...  \n",
      "599                           Spray has no strong odor      good smell  \n",
      "600  Spray is nice to keep out on the porch on a su...      good smell  \n",
      "601        Spray does not leave any oily stinky stains      good smell  \n",
      "602  Love that the scent of this spray is not chemi...      good smell  \n",
      "603              Bug spray does not smell nauseating .      good smell  \n",
      "\n",
      "[604 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\skand\\Downloads\\interns-tagging_Skandha.xlsx')\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caf032e",
   "metadata": {},
   "source": [
    "## Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9face172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning( review, remove_stopwords=True):\n",
    "   \n",
    "    \n",
    "\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
    "   \n",
    "    words = review_text.lower().split()\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "\n",
    "    b=[]\n",
    "    stemmer = english_stemmer \n",
    "    for word in words:\n",
    "        b.append(stemmer.stem(word))\n",
    "\n",
    "    \n",
    "    return(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9a4822",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dc22f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_Text = []\n",
    "for review in df['phrase']:\n",
    "    clean_Text.append( \" \".join(cleaning(review)))\n",
    "    \n",
    "clean_summary = []\n",
    "for review in df['common idea']:\n",
    "    clean_summary.append( \" \".join(cleaning(review)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30637460",
   "metadata": {},
   "source": [
    "## Top Word Count In Text(Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed06f5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Count Words Used In Review product      102\n",
      "safe          82\n",
      "use           79\n",
      "smell         72\n",
      "around        57\n",
      "pest          47\n",
      "recommend     46\n",
      "pet           38\n",
      "good          38\n",
      "great         36\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Top_Words_Review =pd.Series(' '.join(clean_Text).lower().split()).value_counts()[:10]\n",
    "print (\"Top Count Words Used In Review\", Top_Words_Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14e5f6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Count Words Used In Summary effici     142\n",
      "product    142\n",
      "good       141\n",
      "smell      141\n",
      "safe       117\n",
      "kid        117\n",
      "pet        117\n",
      "loyal       62\n",
      "custom      62\n",
      "valu        61\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Top_Words_Summary = pd.Series(' '.join(clean_summary).lower().split()).value_counts()[:10]\n",
    "print (\"Top Count Words Used In Summary\",Top_Words_Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f936ae3d",
   "metadata": {},
   "source": [
    "# Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39065240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=4, max_features = 10000)\n",
    "vz = vectorizer.fit_transform(clean_Text)\n",
    "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da04e276",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4269d5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: 0.0, \n",
      "neg: 0.0, \n",
      "neu: 1.0, \n",
      "pos: 0.0, \n",
      "would use product need joe\n",
      "compound: 0.0, \n",
      "neg: 0.0, \n",
      "neu: 1.0, \n",
      "pos: 0.0, \n",
      "use product week\n",
      "compound: 0.0, \n",
      "neg: 0.0, \n",
      "neu: 1.0, \n",
      "pos: 0.0, \n",
      "continu use product issu\n",
      "compound: 0.7096, \n",
      "neg: 0.0, \n",
      "neu: 0.253, \n",
      "pos: 0.747, \n",
      "alway good luck product\n",
      "compound: 0.0, \n",
      "neg: 0.0, \n",
      "neu: 1.0, \n",
      "pos: 0.0, \n",
      "continu use product product get job done\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "Senti = SentimentIntensityAnalyzer()\n",
    "sample_review = clean_Text[:5]\n",
    "for sentence in sample_review:\n",
    "    sentence\n",
    "    ss = Senti.polarity_scores(sentence)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]))\n",
    "    print(sentence) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be4030",
   "metadata": {},
   "source": [
    "## K means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c1b4d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " recommend\n",
      " would\n",
      " friend\n",
      " product\n",
      " anyon\n",
      "\n",
      "Cluster 1:\n",
      " safe\n",
      " around\n",
      " kid\n",
      " children\n",
      " use\n",
      "\n",
      "Cluster 2:\n",
      " smell\n",
      " chemic\n",
      " work\n",
      " bad\n",
      " spray\n",
      "\n",
      "Cluster 3:\n",
      " odor\n",
      " product\n",
      " strong\n",
      " bad\n",
      " effect\n",
      "\n",
      "Cluster 4:\n",
      " price\n",
      " great\n",
      " good\n",
      " worth\n",
      " afford\n",
      "\n",
      "Cluster 5:\n",
      " pet\n",
      " friend\n",
      " safe\n",
      " stuff\n",
      " good\n",
      "\n",
      "Cluster 6:\n",
      " scent\n",
      " strong\n",
      " lemon\n",
      " fresh\n",
      " nice\n",
      "\n",
      "Cluster 7:\n",
      " use\n",
      " product\n",
      " year\n",
      " sever\n",
      " continu\n",
      "\n",
      "Cluster 8:\n",
      " bug\n",
      " ant\n",
      " deliveri\n",
      " valu\n",
      " fast\n",
      "\n",
      "Cluster 9:\n",
      " pest\n",
      " control\n",
      " awesom\n",
      " effect\n",
      " keep\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "num_clusters = 10\n",
    "kmeans_model = MiniBatchKMeans(n_clusters=num_clusters, init='k-means++', n_init=1, \n",
    "                         init_size=1000, batch_size=1000, verbose=False, max_iter=1000)\n",
    "kmeans = kmeans_model.fit(vz)\n",
    "kmeans_clusters = kmeans.predict(vz)\n",
    "kmeans_distances = kmeans.transform(vz)\n",
    "sorted_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d:\" % i)\n",
    "    for j in sorted_centroids[i, :5]:\n",
    "        print(' %s' % terms[j])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95236ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a88418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b2a861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
